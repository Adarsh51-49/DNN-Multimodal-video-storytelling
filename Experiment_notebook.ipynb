{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db4b2e79",
   "metadata": {},
   "source": [
    "# Improving Long-Range Multimodal Video Storytelling Using Transformer-Based Architectures\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project is about generating stories from videos using both images and text. A common method is to use CNN models to extract image features and LSTM models to understand the sequence over time.\n",
    "\n",
    "LSTM-based models work well for short videos but face problems when the video is long. Important information from earlier frames can be lost, which results in incomplete or unclear captions.\n",
    "\n",
    "To solve this problem, this project uses a Transformer-based model. Transformers use attention to look at all frames together, which helps the model understand long videos and produce more meaningful stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88819cfb",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "## Dataset\n",
    "\n",
    "This project uses the StoryReasoning Dataset. The dataset contains sequences of images along with their corresponding text descriptions, which together form a visual story.\n",
    "\n",
    "Each sequence is treated as a video, and the task is to predict the next part of the story based on previous images and text. To avoid data leakage, the data is split at the video level.\n",
    "\n",
    "- Training data: 80%\n",
    "- Validation data: 10%\n",
    "- Test data: 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f132f2",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "The baseline model follows a traditional approach for video storytelling. It uses a CNN model to extract features from each image and an LSTM model to process the sequence over time.\n",
    "\n",
    "The CNN helps in understanding the visual content of each frame, while the LSTM captures the order of frames in the video. However, this model has difficulty handling long video sequences, as the LSTM may forget important information from earlier frames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28567aa3",
   "metadata": {},
   "source": [
    "## Proposed Transformer-Based Model\n",
    "\n",
    "To improve performance on long video sequences, this project uses a Transformer-based model instead of an LSTM-based model.\n",
    "\n",
    "The Transformer uses an attention mechanism that allows it to focus on all frames in the video at the same time. This helps the model remember important information from earlier frames and understand long-range relationships in the story.\n",
    "\n",
    "By using this approach, the model is expected to generate more complete and meaningful captions for long videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c5d794",
   "metadata": {},
   "source": [
    "## Experimental Setup\n",
    "\n",
    "The performance of the proposed Transformer-based model is compared with the baseline LSTM-based model.\n",
    "\n",
    "The dataset is divided into training, validation, and test sets. The training set is used to learn model parameters, the validation set is used to monitor performance during training, and the test set is used for final evaluation.\n",
    "\n",
    "To evaluate the models, standard captioning metrics are used along with qualitative analysis to check how well the generated stories make sense over long video sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3819db72",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
