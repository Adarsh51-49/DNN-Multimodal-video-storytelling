{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db4b2e79",
   "metadata": {},
   "source": [
    "# Improving Long-Range Multimodal Video Storytelling Using Transformer-Based Architectures\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project is about generating stories from videos using both images and text. A common method is to use CNN models to extract image features and LSTM models to understand the sequence over time.\n",
    "\n",
    "LSTM-based models work well for short videos but face problems when the video is long. Important information from earlier frames can be lost, which results in incomplete or unclear captions.\n",
    "\n",
    "To solve this problem, this project uses a Transformer-based model. Transformers use attention to look at all frames together, which helps the model understand long videos and produce more meaningful stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88819cfb",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "## Dataset\n",
    "\n",
    "This project uses the StoryReasoning Dataset. The dataset contains sequences of images along with their corresponding text descriptions, which together form a visual story.\n",
    "\n",
    "Each sequence is treated as a video, and the task is to predict the next part of the story based on previous images and text. To avoid data leakage, the data is split at the video level.\n",
    "\n",
    "- Training data: 80%\n",
    "- Validation data: 10%\n",
    "- Test data: 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f132f2",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "The baseline model follows a traditional approach for video storytelling. It uses a CNN model to extract features from each image and an LSTM model to process the sequence over time.\n",
    "\n",
    "The CNN helps in understanding the visual content of each frame, while the LSTM captures the order of frames in the video. However, this model has difficulty handling long video sequences, as the LSTM may forget important information from earlier frames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28567aa3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
